import requests
import re
from packaging import version
import time
from bs4 import BeautifulSoup

# é…ç½®ä»£ç† (æ ¹æ®éœ€è¦ä¿®æ”¹)
proxies = {
    "http": "http://127.0.0.1:7788",  # ç¤ºä¾‹ï¼Œæ ¹æ®ä½ çš„å®é™…ä»£ç†è®¾ç½®ä¿®æ”¹
    "https": "https://127.0.0.1:7788", # ç¤ºä¾‹
}
proxies = None  # ä¸ä½¿ç”¨ä»£ç†

# å®šä¹‰å½“å‰ç‰ˆæœ¬
current_versions = {
    "zlib": "1.3.1",
    "zstd": "1.5.6",
    "gmp": "6.3.0",
    "isl": "0.27",
    "mpfr": "4.2.1",
    "mpc": "1.3.1",
    "binutils": "2.44",
    "gcc": "14.2.0",
    "nettle": "3.10.1",
    "libtasn1": "4.20.0",
    "libunistring": "1.3",
    "gpg-error": "1.51",
    "libassuan": "3.0.1",
    "gpgme": "1.24.2",
    "c-ares": "1.34.4",
    "libiconv": "1.18",
    "libidn2": "2.3.0",
    "libpsl": "0.21.5",
    "pcre2": "10.45",
    "expat": "2.6.4",
    "libmetalink": "0.1.3",
    "gnutls": "3.8.9",
    "nghttp2": "1.64.0",
    "libmicrohttpd": "1.0.1",
    "zlib-ng": "2.2.4",
    "libssh2": "1.11.1",
    "libxml2": "2.13.5",
    "xz": "5.6.4",
    "sqlite": "3.49.0",
}

# é‡è¯•å‡½æ•° (æ”¯æŒä»£ç†) - **ä¿®æ”¹ï¼šç§»é™¤ retry å†…éƒ¨çš„æ‰“å°**
def retry(func, url, max_retries=5, delay=2, proxies=None, program=None):
    attempts = 0
    while attempts < max_retries:
        try:
            response = func(url, proxies=proxies)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            attempts += 1
            if attempts == max_retries: # åªåœ¨æœ€ç»ˆå¤±è´¥æ—¶æ‰æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å¤–å±‚å¾ªç¯çš„ except å—å¤„ç†
                raise e
            time.sleep(delay)

# è·å–æœ€æ–°ç‰ˆæœ¬çš„å‡½æ•° (æ”¯æŒä»£ç†)
def get_latest_version(program, proxies=None):
    if program == "zlib":
        url = "https://api.github.com/repos/madler/zlib/releases/latest1"  # æ•…æ„ä½¿ç”¨é”™è¯¯çš„ URL æµ‹è¯•é”™è¯¯å¤„ç†
        response = retry(requests.get, url, proxies=proxies,program=program)
        data = response.json()
        latest_version = data["tag_name"].lstrip("v")
        download_url = data["assets"][0]["browser_download_url"]
        return latest_version, download_url

    elif program == "zstd":
        url = "https://api.github.com/repos/facebook/zstd/releases/latest"
        response = retry(requests.get, url, proxies=proxies,program=program)
        data = response.json()
        latest_version = data["tag_name"].lstrip("v")
        download_url = data["assets"][0]["browser_download_url"]
        return latest_version, download_url

    elif program == "gmp":
        url = "https://ftp.gnu.org/gnu/gmp/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="gmp-([0-9.]+)\.tar\.(xz|gz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/gmp/gmp-{latest_version}.tar.xz"
        return latest_version, download_url

    elif program == "isl":
        url = "https://libisl.sourceforge.io/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="isl-([\d.]+)\.tar\.xz"', response.text)
        if not matches:
            return current_versions["isl"], f"https://libisl.sourceforge.io/isl-{current_versions['isl']}.tar.xz"
        latest_version = max(matches, key=version.parse)
        download_url = f"https://libisl.sourceforge.io/isl-{latest_version}.tar.xz"
        return latest_version, download_url

    elif program == "mpfr":
        url = "https://ftp.gnu.org/gnu/mpfr/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="mpfr-([0-9.]+)\.tar\.(xz|gz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/mpfr/mpfr-{latest_version}.tar.xz"
        return latest_version, download_url

    elif program == "mpc":
        url = "https://ftp.gnu.org/gnu/mpc/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="mpc-([0-9.]+)\.tar\.(gz|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/mpc/mpc-{latest_version}.tar.gz"
        return latest_version, download_url

    elif program == "binutils":
        url = "https://ftp.gnu.org/gnu/binutils/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="binutils-([0-9.]+)\.tar\.(xz|gz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/binutils/binutils-{latest_version}.tar.xz"
        return latest_version, download_url

    elif program == "gcc":
        url = "https://ftp.gnu.org/gnu/gcc/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="gcc-([0-9.]+)/"', response.text)
        if not matches:
            return current_versions["gcc"], f"https://ftp.gnu.org/gnu/gcc/gcc-{current_versions['gcc']}/gcc-{current_versions['gcc']}.tar.xz"

        version_matches = [m for m in matches if re.match(r"^\d+(\.\d+)+$", m)]
        if not version_matches:
            return current_versions["gcc"], f"https://ftp.gnu.org/gnu/gcc/gcc-{current_versions['gcc']}/gcc-{current_versions['gcc']}.tar.xz"

        latest_version = max(version_matches, key=version.parse)
        download_url = f"https://ftp.gnu.org/gnu/gcc/gcc-{latest_version}/gcc-{latest_version}.tar.xz"
        return latest_version, download_url

    elif program == "nettle":
        url = "https://ftp.gnu.org/gnu/nettle/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="nettle-([0-9.]+)\.tar\.(gz|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/nettle/nettle-{latest_version}.tar.gz" # Correct URL - using latest_version
        return latest_version, download_url


    elif program == "libtasn1":
        url = "https://ftp.gnu.org/gnu/libtasn1/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="libtasn1-([0-9.]+)\.tar\.(gz|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/libtasn1/libtasn1-{latest_version}.tar.gz" # Correct URL - using latest_version
        return latest_version, download_url

    elif program == "libunistring":
        url = "https://ftp.gnu.org/gnu/libunistring/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="libunistring-([0-9.]+)\.tar\.(gz|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/libunistring/libunistring-{latest_version}.tar.gz" # Correct URL - using latest_version
        return latest_version, download_url

    elif program == "gpg-error":
        url = "https://www.gnupg.org/ftp/gcrypt/libgpg-error/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="libgpg-error-([0-9.]+)\.tar\.(gz|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://www.gnupg.org/ftp/gcrypt/libgpg-error/libgpg-error-{latest_version}.tar.gz" # Correct URL - using latest_version
        return latest_version, download_url

    elif program == "libassuan":
        url = "https://www.gnupg.org/ftp/gcrypt/libassuan/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="libassuan-([0-9.]+)\.tar\.(bz2|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://www.gnupg.org/ftp/gcrypt/libassuan/libassuan-{latest_version}.tar.bz2" # Correct URL - using latest_version
        return latest_version, download_url

    elif program == "gpgme":
        url = "https://www.gnupg.org/ftp/gcrypt/gpgme/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="gpgme-([0-9.]+)\.tar\.(bz2|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://www.gnupg.org/ftp/gcrypt/gpgme/gpgme-{latest_version}.tar.bz2" # Correct URL - using latest_version
        return latest_version, download_url

    elif program == "c-ares":
        url = "https://api.github.com/repos/c-ares/c-ares/releases/latest"
        response = retry(requests.get, url, proxies=proxies,program=program)
        data = response.json()
        latest_version = data["tag_name"].lstrip("v")
        for asset in data["assets"]:
            if asset["name"].endswith(".tar.gz"):
                download_url = asset["browser_download_url"]
                return latest_version, download_url
        download_url = data["assets"][0]["browser_download_url"]
        return latest_version, download_url

    elif program == "libiconv":
        url = "https://ftp.gnu.org/gnu/libiconv/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="libiconv-([0-9.]+)\.tar\.(gz|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/libiconv/libiconv-{latest_version}.tar.gz" # Correct URL - using latest_version
        return latest_version, download_url

    elif program == "libidn2":
        url = "https://ftp.gnu.org/gnu/libidn/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="libidn2-([0-9.]+)\.tar\.(gz|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/libidn/libidn2-{latest_version}.tar.gz" # Correct URL - using latest_version
        return latest_version, download_url

    elif program == "libpsl":
        url = "https://api.github.com/repos/rockdaboot/libpsl/releases/latest"
        response = retry(requests.get, url, proxies=proxies,program=program)
        data = response.json()
        latest_version = data["tag_name"].lstrip("v")
        download_url = data["assets"][0]["browser_download_url"]
        return latest_version, download_url

    elif program == "pcre2":
        url = "https://api.github.com/repos/PCRE2Project/pcre2/releases/latest"
        response = retry(requests.get, url, proxies=proxies,program=program)
        data = response.json()
        latest_version = data["tag_name"].replace('pcre2-', '')
        download_url = data["assets"][0]["browser_download_url"]
        return latest_version, download_url

    elif program == "expat":
        url = "https://api.github.com/repos/libexpat/libexpat/releases/latest"
        response = retry(requests.get, url, proxies=proxies,program=program)
        data = response.json()
        latest_version = data["tag_name"].lstrip("R_").replace('_', '.')
        download_url = data["assets"][0]["browser_download_url"]
        return latest_version, download_url

    elif program == "libmetalink":
        url = "https://api.github.com/repos/metalink-dev/libmetalink/releases/latest"
        response = retry(requests.get, url, proxies=proxies,program=program)
        data = response.json()
        latest_version = data["tag_name"].lstrip("release-")
        download_url = data["assets"][0]["browser_download_url"]
        return latest_version, download_url

    elif program == "gnutls":
        base_url = "https://www.gnupg.org/ftp/gcrypt/gnutls/" # è¿”å›åˆ°åŸºç¡€ URL ä»¥åˆ—å‡ºç‰ˆæœ¬
        response = retry(requests.get, base_url, proxies=proxies,program=program)
        version_dir_matches = re.findall(r'href="v([\d.]+)"', response.text) # å†æ¬¡æŸ¥æ‰¾ç‰ˆæœ¬ç›®å½•
        if not version_dir_matches:
            return current_versions["gnutls"], f"https://www.gnupg.org/ftp/gcrypt/gnutls/gnutls-{current_versions['gnutls']}.tar.xz"
        latest_version_dir = max(version_dir_matches, key=version.parse) # è·å–æœ€æ–°çš„ç‰ˆæœ¬ç›®å½•
        version_url = base_url + f"v{latest_version_dir}/" # æ„å»ºæœ€æ–°çš„ç‰ˆæœ¬ç›®å½•çš„ URL
        version_response = retry(requests.get, version_url, proxies=proxies,program=program) # è·å–æœ€æ–°çš„ç‰ˆæœ¬ç›®å½•é¡µé¢
        matches = re.findall(r'href="gnutls-([\d.]+)\.tar\.xz"', version_response.text) # åœ¨æœ€æ–°çš„ç‰ˆæœ¬ç›®å½•ä¸­æŸ¥æ‰¾ tar.xz æ–‡ä»¶
        if not matches:
             return current_versions["gnutls"], f"https://www.gnupg.org/ftp/gcrypt/gnutls/gnutls-{current_versions['gnutls']}.tar.xz"
        latest_version = max(matches, key=version.parse) # Corrected max call with version.parse as key
        download_url = f"https://www.gnupg.org/ftp/gcrypt/gnutls/v{latest_version_dir}/gnutls-{latest_version}.tar.xz" # ä½¿ç”¨æœ€æ–°çš„ç‰ˆæœ¬ç›®å½•æ„å»ºæ­£ç¡®çš„ URL
        return latest_version, download_url

    elif program == "nghttp2":
        url = "https://api.github.com/repos/nghttp2/nghttp2/releases/latest"
        response = retry(requests.get, url, proxies=proxies,program=program)
        data = response.json()
        latest_version = data["tag_name"].lstrip("v")
        for asset in data["assets"]:
            if asset["name"].endswith(".tar.gz"):
                download_url = asset["browser_download_url"]
                return latest_version, download_url
        download_url = data["assets"][0]["browser_download_url"] # Fallback
        return latest_version, download_url


    elif program == "libmicrohttpd":
        url = "https://ftp.gnu.org/gnu/libmicrohttpd/"
        response = retry(requests.get, url, proxies=proxies,program=program)
        matches = re.findall(r'href="libmicrohttpd-([0-9.]+)\.tar\.(gz|xz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://ftp.gnu.org/gnu/libmicrohttpd/libmicrohttpd-{latest_version}.tar.gz"
        return latest_version, download_url

    elif program == "zlib-ng":
        url = "https://api.github.com/repos/zlib-ng/zlib-ng/releases/latest"
        response = retry(requests.get, url, proxies=proxies, program=program)
        data = response.json()
        latest_version = data["tag_name"].lstrip("v")
        download_url = data["assets"][0]["browser_download_url"]
        return latest_version, download_url

    elif program == "libssh2":
        url = "https://libssh2.org/download/"
        response = retry(requests.get, url, proxies=proxies, program=program)
        matches = re.findall(r'href="libssh2-([0-9.]+)\.tar\.(xz|gz)"', response.text)
        latest_version = max(matches, key=lambda x: version.parse(x[0]))[0]
        download_url = f"https://libssh2.org/download/libssh2-{latest_version}.tar.xz"
        return latest_version, download_url

    elif program == "libxml2":
        base_url = "https://download.gnome.org/sources/libxml2/"
        response = retry(requests.get, base_url, program=program, proxies=proxies)
        html = response.text
        main_versions = re.findall(r'href="(\d+\.\d+/)"', html)
        main_versions = [v.strip('/') for v in main_versions]
        main_versions.sort(key=lambda v: version.parse(v), reverse=True)
        latest_main = main_versions[0]
        response = retry(requests.get, f"{base_url}{latest_main}/", program=program, proxies=proxies)
        html = response.text
        files = re.findall(r'href="(libxml2-(\d+\.\d+\.\d+)\.tar\.xz)"', html)
        latest_file = max(files, key=lambda x: version.parse(x[1]))
        download_url = f"{base_url}{latest_main}/{latest_file[0]}"
        latest_version = latest_file[1]
        return latest_version, download_url

    elif program == "xz":
        url = "https://sourceforge.net/projects/lzmautils/files/"
        response = retry(requests.get, url, program=program, proxies=proxies)
        html = response.text
        match = re.search(r'xz-([0-9.]+)\.tar\.gz', html)
        if not match:
            raise ValueError(f"xz: æœªæ‰¾åˆ°ç‰ˆæœ¬å·")
        latest_version = match.group(1)
        download_url = f"https://sourceforge.net/projects/lzmautils/files/xz-{latest_version}.tar.xz"
        return latest_version, download_url


    elif program == "sqlite":
        # è·å–æœ€æ–°ç‰ˆæœ¬å·
        index_url = "https://www.sqlite.org/index.html"
        response = retry(requests.get, index_url, proxies=proxies)
        html = response.text
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç‰ˆæœ¬å·
        version_match = re.search(r'>Version ([0-9.]+)<', html)
        if not version_match:
            return None, None
        latest_version = version_match.group(1)

        # è·å–ä¸‹è½½é¡µé¢å†…å®¹
        download_url = "https://www.sqlite.org/download.html"
        response = retry(requests.get, download_url, proxies=proxies)
        html = response.text

        # æå– CSV æ•°æ®éƒ¨åˆ†
        csv_data = re.search(r'Download product data for scripts to read(.*?)-->', html, re.DOTALL)
        if not csv_data:
            return None, None

        # æå– autoconf çš„ tar.gz æ–‡ä»¶é“¾æ¥
        tarball_match = re.search(r'autoconf.*?\.tar\.gz', csv_data.group(1))
        if not tarball_match:
            return None, None

        # æ„å»ºå®Œæ•´çš„ä¸‹è½½é“¾æ¥
        tarball_url = tarball_match.group(0)
        download_url = f"https://www.sqlite.org/{tarball_url}"
        return latest_version, download_url


    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ç¨‹åº: {program}")

# æ£€æŸ¥æ›´æ–°
update_found = False
error_messages = [] # åˆå§‹åŒ–é”™è¯¯æ¶ˆæ¯åˆ—è¡¨

# åˆå§‹åŒ–è¡¨æ ¼å¤´
table = "| ç¨‹åº | å½“å‰ç‰ˆæœ¬ | æœ€æ–°ç‰ˆæœ¬ | çŠ¶æ€ | ä¸‹è½½åœ°å€ |\n| --- | --- | --- | --- | --- |\n"

for program, current_version in current_versions.items():
    try:
        latest_version, download_url = get_latest_version(program, proxies=proxies)
        if latest_version is None or download_url is None:  # SQLite check
            error_messages.append(f"- {program}: æ— æ³•è·å–æœ€æ–°ç‰ˆæœ¬ä¿¡æ¯") # æ·»åŠ é”™è¯¯æ¶ˆæ¯åˆ°åˆ—è¡¨
            table += f"| {program} | {current_version} | N/A | âš ï¸ è·å–ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥ | N/A |\n" # æ·»åŠ é”™è¯¯çŠ¶æ€åˆ°è¡¨æ ¼
            continue

        # åˆ¤æ–­æ˜¯å¦æœ‰æ–°ç‰ˆæœ¬
        if version.parse(latest_version) > version.parse(current_version):
            table += f"| {program} | {current_version} | {latest_version} | ğŸ”´ éœ€æ›´æ–° | [ä¸‹è½½é“¾æ¥]({download_url}) |\n"
            update_found = True
        else:
            # ä¿®æ­£ç‚¹ï¼šé—­åˆå¤§æ‹¬å·å¹¶ç§»é™¤å¤šä½™ç¬¦å·
            table += f"| {program} | {current_version} | {latest_version} | å·²æ˜¯æœ€æ–°ç‰ˆ | [ä¸‹è½½é“¾æ¥]({download_url}) |\n"

    except Exception as e:
        error_messages.append(f"- {program} è·å–æœ€æ–°ç‰ˆæœ¬å¤±è´¥: {e}") # æ·»åŠ é”™è¯¯æ¶ˆæ¯åˆ°åˆ—è¡¨
        table += f"| {program} | {current_version} | N/A | âŒ è·å–ç‰ˆæœ¬å¤±è´¥ | N/A |\n" # æ·»åŠ é”™è¯¯çŠ¶æ€åˆ°è¡¨æ ¼

# å…ˆæ‰“å°æ‰€æœ‰é”™è¯¯æ¶ˆæ¯
if error_messages:
    print("--- é”™è¯¯ä¿¡æ¯ ---")
    for msg in error_messages:
        print(msg)
    print("---")

# æ‰“å°å¸¦è¶…é“¾æ¥çš„æ¶ˆæ¯è¡¨æ ¼
print(table)

# å¦‚æœæ²¡æœ‰å‘ç°æ›´æ–°
if not update_found:
    print("- æ£€æµ‹ç»“æŸï¼Œæ‰€æœ‰ç¨‹åºéƒ½æ²¡æœ‰æ›´æ–°çš„ç‰ˆæœ¬")
print("- ******æ£€æµ‹ç»“æŸ******")
